{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPkRjHExMGiN+BRquq18iX8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"5dBCSpq9U7w-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672235288116,"user_tz":-540,"elapsed":700,"user":{"displayName":"Silvia Zhang","userId":"10165716290267475042"}},"outputId":"0698d3ba-c0bd-4ca9-d17b-53bab189131a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[39.9941]], grad_fn=<AddBackward0>)\n","tensor([[39.9941]])\n","39.9941291809082\n"]}],"source":["import torch\n","x_train = torch.FloatTensor([[1,1],[2,2],[3,3]])\n","y_train = torch.FloatTensor([[10],[20],[30]])\n","W = torch.randn([2,1],requires_grad=True)\n","b = torch.randn([1],requires_grad=True) \n","optimizer = torch.optim.SGD([W,b], lr=0.01)\n","\n","def model_LinearRegression(x): \n","  return torch.matmul(x,W)+b \n","  \n","for step in range(2000): \n","  prediction = model_LinearRegression(x_train) # prediction = H(x) in lecture node \n","  cost = torch.mean((prediction - y_train) ** 2)\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","# Here, we are done for the training. Then, see the result. \n","x_test = torch. FloatTensor([[4,4]]) # We should only have one test datapoint at a time\n","model_test = model_LinearRegression(x_test)\n","print(model_test)\n","print(model_test.detach())\n","print(model_test.detach().item())"]},{"cell_type":"markdown","source":[],"metadata":{"id":"K6abmZm0ZTpO"}}]}